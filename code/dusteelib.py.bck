import requests
import sentinelsat
import gdal
import os
from xml.etree import ElementTree as et
import datetime as dt
from sentinelsat.sentinel import SentinelAPI

def clean_downloaded(products,a):
    for product_ID in iter(products):
        product_path = a[0][product_ID]['path']
        if os.path.exists(product_path):
            os.remove(product_path)
        tif = product_path.replace('.zip','.tif')
        if os.path.exists('tmpfile.tif'):
            os.remove('tmpfile.tif')
        if os.path.exists(tif):
            os.remove(tif)
            try:
                os.remove(tif+'.aux.xml')
            except:
                print(tif+'.aux.xml does not exist')

def s5p2geotiff(product_path, product_type):
    if os.path.exists('lon.vrt'):
        os.remove('lon.vrt')
        os.remove('lat.vrt')
        os.remove(product_type+'.vrt')
    if product_type == 'no2':
        strtype='nitrogendioxide_tropospheric_column'
    os.system('gdal_translate -of VRT HDF5:"'+product_path+'"://PRODUCT/longitude lon.vrt')
    os.system('gdal_translate -of VRT HDF5:"'+product_path+'"://PRODUCT/latitude lat.vrt')
    os.system('gdal_translate -of VRT HDF5:"'+product_path+'"://PRODUCT/'+strtype+' '+product_type+'.vrt')
    tree = et.parse(product_type+'.vrt')
    root = tree.getroot()
    xml_geo = et.SubElement(root, 'Metadata')
    xml_geo.attrib["domain"] = 'GEOLOCATION'
    latinfo = et.SubElement(xml_geo, 'mdi')
    latinfo.attrib["key"] = 'X_DATASET'
    latinfo.text = 'lon.vrt'
    latinfo2 = et.SubElement(xml_geo, 'mdi')
    latinfo2.attrib["key"] = 'X_BAND'
    latinfo2.text = '1'
    loninfo = et.SubElement(xml_geo, 'mdi')
    loninfo.attrib["key"] = 'Y_DATASET'
    loninfo.text = 'lat.vrt'
    loninfo2 = et.SubElement(xml_geo, 'mdi')
    loninfo2.attrib["key"] = 'Y_BAND'
    loninfo2.text = '1'
    pixof = et.SubElement(xml_geo, 'mdi')
    pixof.attrib["key"] = 'PIXEL_OFFSET'
    pixof.text = '0'
    linof = et.SubElement(xml_geo, 'mdi')
    linof.attrib["key"] = 'LINE_OFFSET'
    linof.text = '0'
    pixst = et.SubElement(xml_geo, 'mdi')
    pixst.attrib["key"] = 'PIXEL_STEP'
    pixst.text = '1'
    linst = et.SubElement(xml_geo, 'mdi')
    linst.attrib["key"] = 'LINE_STEP'
    linst.text = '1'
    tree.write(product_type+'.vrt')
    outname = product_path.replace('.zip','.tif')
    ds = gdal.Warp(outname, product_type+'.vrt',format = 'GTiff',
               warpOptions = [ 'dstSRS=EPSG:4326', 'geoloc=True', 'srcNodata=9.96921e+36', 'dstNodata=9999'])
    return outname

def s5down(datum = str(dt.date.today()), product_type = 'no2'):
    # this function will download s5p data of given product_type for given date
    # e.g. s5down('2019-08-15','no2')
    datum = dt.datetime.strptime(datum,'%Y-%m-%d').date()
    time_in = dt.datetime.combine(datum, dt.time(0,0))
    time_out = dt.datetime.combine(datum, dt.time(23,59))
    api = SentinelAPI('s5pguest', 's5pguest', 'https://s5phub.copernicus.eu/dhus')
    #coordinates for CZ:
    footprint = 'POLYGON((12.278971773041526 48.69059060056844,18.98957262575027 48.69059060056844,18.98957262575027 51.081759060281655,12.278971773041526 51.081759060281655,12.278971773041526 48.69059060056844))'
    products = api.query(footprint,
                     date = (time_in, time_out),
                     platformname = 'Sentinel-5',
                     producttype='L2__NO2___')
    print('there are '+str(len(products))+' products found')
    a = api.download_all(products)
    geotiffs = []
    for product_ID in iter(products):
        product_path = a[0][product_ID]['path']
        print('converting '+product_path+' to geotiff')
        geotiffs.append(s5p2geotiff(product_path,product_type))
    if not geotiffs:
        print('some error happened, no geotiffs generated')
        clean_downloaded(products,a)
        return None
    tifstring = ''
    for tif in geotiffs:
        tifstring = tifstring + ' '+ tif
    print('merging geotiffs to '+str(datum)+'.tif and cropping for CZ extents')
    outfile = str(datum)+'.tif'
    tmpfile = 'tmp.tif'
    os.system('gdal_merge.py -o merged.tif -of GTiff -ul_lr 11.3867 51.4847 19.943 47.7933 -a_nodata 9999 '+tifstring)
    gdal_calc = 'gdal_calc.py -A merged.tif --outfile=temp1000.tif --calc="(A * 1000)" --overwrite'
    print(gdal_calc)
    os.system(gdal_calc)
    #now oversample using cubic..
    gdalwarp = 'gdalwarp -tr 0.015 0.015 -r cubicspline -dstnodata 9999 -srcnodata 9999 temp1000.tif '+outfile
    #gdalwarp = 'gdalwarp -s_srs EPSG:4326 -t_srs EPSG:4326 -tr 0.015 0.015 -r cubicspline -dstnodata 9999 -srcnodata 9999 temp1000.tif '+outfile
    print(gdalwarp)
    os.system(gdalwarp)
    #cleaning
    clean_downloaded(products,a)
    return geotiffs

def colorize_tif(tiffile):
    palette = """
0.57 103   0  31
0.5 178  24  43
0.438 214  96  77
0.375 244 165 130
0.313 253 219 199
0.25 209 229 240
0.188 146 197 222
0.125 67 147 195
0.062 33 102 172
0  5  48  97
""" 
    if not os.path.exists('pal.txt'):
        with  open('pal.txt','w') as myfile:
            myfile.write(palette)
    gdaldem = 'gdaldem color-relief '+tiffile+' pal.txt -of GTiff temp.tif'
    print(gdaldem)
    os.system(gdaldem)
    os.remove(tiffile)
    os.rename('temp.tif',tiffile)
    #use gdal2tiles.py...

def geocode(address):
    geocode_url = "https://www.google.com/maps/search/{}".format(address)
    results = requests.get(geocode_url)
    page = results.text
    loc = page.find('staticmap?center=')
    stripe = page[loc:loc+100]
    coords = stripe.split('=')[1].split('&')[0]
    lat = coords.split('%2C')[0]
    lon = coords.split('%2C')[1]
    latlon = [float(lat), float(lon)]
    return latlon
